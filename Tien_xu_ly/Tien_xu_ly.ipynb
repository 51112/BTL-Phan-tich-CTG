{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1e9ccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4cefc1",
   "metadata": {},
   "source": [
    "# Xóa những dòng thiếu giá trị"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4a1b01",
   "metadata": {},
   "source": [
    "##### Xử lý nhiều file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33aab67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_1.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_1.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_10.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_10.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_11.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_11.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_12.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_12.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_13.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_13.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_14.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_14.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_15.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_15.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_16.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_16.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_17.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_17.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_18.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_18.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_19.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_19.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_2.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_2.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_20.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_20.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_21.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_21.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_3.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_3.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_4.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_4.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_5.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_5.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_6.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_6.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_7.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_7.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_8.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_8.csv (xóa 0 dòng)\n",
      "Đang xử lý: Doc_file_Jsonl/File_loc\\File_loc_batch_9.csv\n",
      "Đã cập nhật: Doc_file_Jsonl/File_loc\\File_loc_batch_9.csv (xóa 0 dòng)\n"
     ]
    }
   ],
   "source": [
    "# === PHẦN 1: Làm sạch dữ liệu File_loc ===\n",
    "# Định nghĩa thư mục đầu vào và mẫu file\n",
    "input_dir = 'Doc_file_Jsonl/File_loc'\n",
    "pattern = os.path.join(input_dir, 'File_loc_batch_*.csv')\n",
    "\n",
    "# Lặp qua các file CSV để làm sạch\n",
    "for file in glob.glob(pattern):\n",
    "    print(f\"Đang xử lý: {file}\")\n",
    "    df = pd.read_csv(file, dtype={'name': str, 'abstract': str, 'sections': str})\n",
    "    original_len = len(df)\n",
    "    # Xóa các dòng thiếu giá trị ở cột name, abstract, sections\n",
    "    df = df.dropna(subset=['name', 'abstract', 'sections'])\n",
    "    # Kiểm tra tính hợp lệ của sections (phải là danh sách)\n",
    "    valid_sections = df['sections'].apply(lambda x: isinstance(ast.literal_eval(x), list) if pd.notnull(x) else False)\n",
    "    df = df[valid_sections]\n",
    "    # Ghi đè file gốc\n",
    "    df.to_csv(file, index=False)\n",
    "    print(f\"Đã cập nhật: {file} (xóa {original_len - len(df)} dòng)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7badc104",
   "metadata": {},
   "source": [
    "##### Xử lý 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae15af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === PHẦN 1: Làm sạch dữ liệu File_loc ===\n",
    "# # Định nghĩa thư mục đầu vào và mẫu file\n",
    "\n",
    "# input_dir = 'Doc_file_Jsonl/File_loc'\n",
    "# file = os.path.join(input_dir, 'File_loc_batch_1.csv')\n",
    "\n",
    "# print(f\"Đang xử lý: {file}\")\n",
    "# df = pd.read_csv(file, dtype={'name': str, 'abstract': str, 'sections': str})\n",
    "# original_len = len(df)\n",
    "# # Xóa các dòng thiếu giá trị ở cột name, abstract, sections\n",
    "# df = df.dropna(subset=['name', 'abstract', 'sections'])\n",
    "# # Kiểm tra tính hợp lệ của sections (phải là danh sách)\n",
    "# valid_sections = df['sections'].apply(lambda x: isinstance(ast.literal_eval(x), list) if pd.notnull(x) else False)\n",
    "# df = df[valid_sections]\n",
    "# # Ghi đè file gốc\n",
    "# df.to_csv(file, index=False)\n",
    "# print(f\"Đã cập nhật: {file} (xóa {original_len - len(df)} dòng)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26880d9c",
   "metadata": {},
   "source": [
    "# Tính điểm tổng hợp độ quan trọng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2611a5a",
   "metadata": {},
   "source": [
    "##### Tính điểm nhiều file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7408d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Xử lý File_loc_batch_1.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_1.csv\n",
      "🔍 Xử lý File_loc_batch_10.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_10.csv\n",
      "🔍 Xử lý File_loc_batch_11.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_11.csv\n",
      "🔍 Xử lý File_loc_batch_12.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_12.csv\n",
      "🔍 Xử lý File_loc_batch_13.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_13.csv\n",
      "🔍 Xử lý File_loc_batch_14.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_14.csv\n",
      "🔍 Xử lý File_loc_batch_15.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_15.csv\n",
      "🔍 Xử lý File_loc_batch_16.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_16.csv\n",
      "🔍 Xử lý File_loc_batch_17.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_17.csv\n",
      "🔍 Xử lý File_loc_batch_18.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_18.csv\n",
      "🔍 Xử lý File_loc_batch_19.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_19.csv\n",
      "🔍 Xử lý File_loc_batch_2.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_2.csv\n",
      "🔍 Xử lý File_loc_batch_20.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_20.csv\n",
      "🔍 Xử lý File_loc_batch_21.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_21.csv\n",
      "🔍 Xử lý File_loc_batch_3.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_3.csv\n",
      "🔍 Xử lý File_loc_batch_4.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_4.csv\n",
      "🔍 Xử lý File_loc_batch_5.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_5.csv\n",
      "🔍 Xử lý File_loc_batch_6.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_6.csv\n",
      "🔍 Xử lý File_loc_batch_7.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_7.csv\n",
      "🔍 Xử lý File_loc_batch_8.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_8.csv\n",
      "🔍 Xử lý File_loc_batch_9.csv...\n",
      "✅ Đã lưu: Diem_TF-IDF\\Diem_TF-IDF_batch_9.csv\n"
     ]
    }
   ],
   "source": [
    "# === PHẦN 2: Tính điểm TF-IDF ===\n",
    "# Hàm trích xuất văn bản từ sections\n",
    "def extract_text_from_sections(sections):\n",
    "    text_parts = []\n",
    "    if isinstance(sections, list):\n",
    "        for section in sections:\n",
    "            if 'name' in section:\n",
    "                text_parts.append(str(section['name']))\n",
    "            if 'has_parts' in section:\n",
    "                for part in section['has_parts']:\n",
    "                    if isinstance(part, dict) and 'value' in part:\n",
    "                        text_parts.append(str(part['value']))\n",
    "    return ' '.join(text_parts)\n",
    "\n",
    "# Hàm kết hợp văn bản từ name, abstract và sections\n",
    "def combine_text(row):\n",
    "    name = row['name'] if pd.notna(row['name']) else \"\"\n",
    "    abstract = row['abstract'] if pd.notna(row['abstract']) else \"\"\n",
    "    try:\n",
    "        sections = ast.literal_eval(row['sections']) if pd.notna(row['sections']) else []\n",
    "        sections_text = extract_text_from_sections(sections)\n",
    "    except Exception:\n",
    "        sections_text = \"\"\n",
    "    return f\"{name} {abstract} {sections_text}\"\n",
    "\n",
    "# Tạo thư mục lưu điểm TF-IDF\n",
    "output_dir = 'Diem_TF-IDF'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Từ điển lưu điểm TF-IDF của các title\n",
    "valid_names_scores = {}\n",
    "\n",
    "# Xử lý từng file CSV để tính TF-IDF\n",
    "for filename in sorted(os.listdir(input_dir)):\n",
    "    if filename.startswith('File_loc_batch_') and filename.endswith('.csv'):\n",
    "        filepath = os.path.join(input_dir, filename)\n",
    "        print(f\"🔍 Xử lý {filename}...\")\n",
    "        df = pd.read_csv(filepath, dtype={'name': str, 'abstract': str, 'sections': str})\n",
    "        # Tạo cột full_text từ name, abstract, sections\n",
    "        df['full_text'] = df.apply(combine_text, axis=1)\n",
    "        # Tính TF-IDF\n",
    "        vectorizer = TfidfVectorizer(max_features=1000)\n",
    "        tfidf_matrix = vectorizer.fit_transform(df['full_text'])\n",
    "        df['tfidf_score'] = tfidf_matrix.mean(axis=1).A1\n",
    "        # Chuẩn hóa điểm TF-IDF về [0,1]\n",
    "        scaler = MinMaxScaler()\n",
    "        df['tfidf_score'] = scaler.fit_transform(df[['tfidf_score']])\n",
    "        # Lấy số batch từ tên file\n",
    "        batch_num = re.search(r'batch_(\\d+)', filename).group(1)\n",
    "        output_path = os.path.join(output_dir, f'Diem_TF-IDF_batch_{batch_num}.csv')\n",
    "        # Lưu kết quả TF-IDF\n",
    "        df[['name', 'tfidf_score']].to_csv(output_path, index=False)\n",
    "        # Lưu điểm TF-IDF vào từ điển\n",
    "        for _, row in df.iterrows():\n",
    "            valid_names_scores[row['name']] = row['tfidf_score']\n",
    "        print(f\"✅ Đã lưu: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2701c4",
   "metadata": {},
   "source": [
    "##### Tính điểm 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdea1b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === PHẦN 2: Tính điểm TF-IDF ===\n",
    "# # Hàm trích xuất văn bản từ sections\n",
    "# def extract_text_from_sections(sections):\n",
    "#     text_parts = []\n",
    "#     if isinstance(sections, list):\n",
    "#         for section in sections:\n",
    "#             if 'name' in section:\n",
    "#                 text_parts.append(str(section['name']))\n",
    "#             if 'has_parts' in section:\n",
    "#                 for part in section['has_parts']:\n",
    "#                     if isinstance(part, dict) and 'value' in part:\n",
    "#                         text_parts.append(str(part['value']))\n",
    "#     return ' '.join(text_parts)\n",
    "\n",
    "# # Hàm kết hợp văn bản từ name, abstract và sections\n",
    "# def combine_text(row):\n",
    "#     name = row['name'] if pd.notna(row['name']) else \"\"\n",
    "#     abstract = row['abstract'] if pd.notna(row['abstract']) else \"\"\n",
    "#     try:\n",
    "#         sections = ast.literal_eval(row['sections']) if pd.notna(row['sections']) else []\n",
    "#         sections_text = extract_text_from_sections(sections)\n",
    "#     except Exception:\n",
    "#         sections_text = \"\"\n",
    "#     return f\"{name} {abstract} {sections_text}\"\n",
    "\n",
    "# # Tạo thư mục lưu điểm TF-IDF\n",
    "# output_dir = 'Diem_TF-IDF'\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # Từ điển lưu điểm TF-IDF của các title\n",
    "# valid_names_scores = {}\n",
    "\n",
    "# # Xử lý file CSV để tính TF-IDF\n",
    "# filename = os.path.basename(file)\n",
    "# print(f\"🔍 Xử lý {filename}...\")\n",
    "# df = pd.read_csv(file, dtype={'name': str, 'abstract': str, 'sections': str})\n",
    "# # Tạo cột full_text từ name, abstract, sections\n",
    "# df['full_text'] = df.apply(combine_text, axis=1)\n",
    "# # Tính TF-IDF\n",
    "# vectorizer = TfidfVectorizer(max_features=1000)\n",
    "# tfidf_matrix = vectorizer.fit_transform(df['full_text'])\n",
    "# df['tfidf_score'] = tfidf_matrix.mean(axis=1).A1\n",
    "# # Chuẩn hóa điểm TF-IDF về [0,1]\n",
    "# scaler = MinMaxScaler()\n",
    "# df['tfidf_score'] = scaler.fit_transform(df[['tfidf_score']])\n",
    "# # Lấy số batch từ tên file\n",
    "# batch_num = re.search(r'batch_(\\d+)', filename).group(1)\n",
    "# output_path = os.path.join(output_dir, f'Diem_TF-IDF_batch_{batch_num}.csv')\n",
    "# # Lưu kết quả TF-IDF\n",
    "# df[['name', 'tfidf_score']].to_csv(output_path, index=False)\n",
    "# # Lưu điểm TF-IDF vào từ điển\n",
    "# for _, row in df.iterrows():\n",
    "#     valid_names_scores[row['name']] = row['tfidf_score']\n",
    "# print(f\"✅ Đã lưu: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14a39b9",
   "metadata": {},
   "source": [
    "## File Crawl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3304d519",
   "metadata": {},
   "source": [
    "##### Xử lý 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a98f6534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Xử lý file: Crawl_raw_batch_4.csv ===\n",
      "Batch 4: Lọc từ 47640550 → 47538893 dòng\n",
      "Batch 4: Sau khi lọc missing days < 30%, còn 38751822 dòng (10605 titles)\n",
      "🔍 Cột trước khi lưu: ['title', 'date', 'views', 'day_of_week', 'month', 'quarter', 'tfidf_score']\n",
      "🔍 Dữ liệu mẫu:\n",
      "                  title       date  views  day_of_week  month  quarter  \\\n",
      "672  Rossa Mediterranea 2024-01-01    2.0            0      1        1   \n",
      "673  Rossa Mediterranea 2024-01-02    1.0            1      1        1   \n",
      "674  Rossa Mediterranea 2024-01-03    2.0            2      1        1   \n",
      "675  Rossa Mediterranea 2024-01-04    1.0            3      1        1   \n",
      "676  Rossa Mediterranea 2024-01-05    0.0            4      1        1   \n",
      "\n",
      "     tfidf_score  \n",
      "672     0.465878  \n",
      "673     0.465878  \n",
      "674     0.465878  \n",
      "675     0.465878  \n",
      "676     0.465878  \n",
      "✅ Đã lưu file long cho ARIMA, TFT, Informer: Crawl(2)\\Crawl_ca_nam_long\\Crawl_full_views_ca_nam_batch_4.csv (38751822 dòng)\n",
      "🎉 Hoàn tất xử lý file!\n"
     ]
    }
   ],
   "source": [
    "# === PHẦN 3: Xử lý file Crawl ===\n",
    "# Định nghĩa thư mục và cấu hình\n",
    "raw_folder = \"Crawl(2)/Crawl_raw\"\n",
    "output_folder = os.path.join(\"Crawl(2)\", \"Crawl_ca_nam_long\")\n",
    "\n",
    "# Tạo thư mục nếu chưa có\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Xử lý một file cụ thể\n",
    "file = os.path.join(raw_folder, \"Crawl_raw_batch_4.csv\")\n",
    "batch_number = 4\n",
    "\n",
    "if not os.path.exists(file):\n",
    "    raise FileNotFoundError(f\"Không tìm thấy file: {file}\")\n",
    "\n",
    "print(f\"\\n=== Xử lý file: {os.path.basename(file)} ===\")\n",
    "\n",
    "# Đọc và lọc dữ liệu\n",
    "df = pd.read_csv(file, dtype={'title': str, 'views': 'float32'})\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y%m%d', errors='coerce')\n",
    "df.dropna(subset=['date'], inplace=True)\n",
    "\n",
    "original_len = len(df)\n",
    "df = df[df['title'].isin(valid_names_scores.keys())]\n",
    "print(f\"Batch {batch_number}: Lọc từ {original_len} → {len(df)} dòng\")\n",
    "\n",
    "if df.empty:\n",
    "    print(f\"Batch {batch_number}: Bỏ qua vì không có title nào khớp\")\n",
    "else:\n",
    "    # === Lọc các title có số ngày bị thiếu dưới 30% ===\n",
    "    # Tính khoảng ngày mong đợi (từ ngày nhỏ nhất đến lớn nhất trong dữ liệu)\n",
    "    min_date = df['date'].min()\n",
    "    max_date = df['date'].max()\n",
    "    expected_days = (max_date - min_date).days + 1  # Tổng số ngày mong đợi\n",
    "\n",
    "    # Tính số ngày thực tế và tỷ lệ thiếu cho mỗi title\n",
    "    title_day_counts = df.groupby('title')['date'].nunique().reset_index(name='actual_days')\n",
    "    title_day_counts['missing_days'] = expected_days - title_day_counts['actual_days']\n",
    "    title_day_counts['missing_ratio'] = title_day_counts['missing_days'] / expected_days\n",
    "\n",
    "    # Lọc các title có tỷ lệ thiếu dưới 30%\n",
    "    valid_titles = title_day_counts[title_day_counts['missing_ratio'] < 0.3]['title']\n",
    "    df = df[df['title'].isin(valid_titles)]\n",
    "    print(f\"Batch {batch_number}: Sau khi lọc missing days < 30%, còn {len(df)} dòng ({len(valid_titles)} titles)\")\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"Batch {batch_number}: Bỏ qua vì không có title nào thỏa mãn điều kiện missing days\")\n",
    "    else:\n",
    "        # Thêm đặc trưng cho mô hình\n",
    "        df['day_of_week'] = df['date'].dt.dayofweek.astype(np.int8)\n",
    "        df['month'] = df['date'].dt.month.astype(np.int8)\n",
    "        df['quarter'] = df['date'].dt.quarter.astype(np.int8)\n",
    "        df['tfidf_score'] = df['title'].map(valid_names_scores)\n",
    "\n",
    "        # Kiểm tra dữ liệu trước khi lưu\n",
    "        print(f\"🔍 Cột trước khi lưu: {list(df.columns)}\")\n",
    "        print(f\"🔍 Dữ liệu mẫu:\\n{df.head()}\")\n",
    "\n",
    "        # Lưu dữ liệu long cho cả ba mô hình (ARIMA, TFT, Informer)\n",
    "        output_path = os.path.join(output_folder, f\"Crawl_full_views_ca_nam_batch_{batch_number}.csv\")\n",
    "        df[['date', 'title', 'views', 'day_of_week', 'month', 'quarter', 'tfidf_score']].to_csv(output_path, index=False)\n",
    "        print(f\"✅ Đã lưu file long cho ARIMA, TFT, Informer: {output_path} ({len(df)} dòng)\")\n",
    "\n",
    "print(\"🎉 Hoàn tất xử lý file!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
